# OpenTelemetry Collector Configuration
# =====================================
# This file configures how the OTel Collector handles telemetry data.
# The collector follows a pipeline model: Receivers → Processors → Exporters
#
# Think of it like a data pipeline:
# 1. RECEIVERS: "Where does data come from?" (your FastAPI app)
# 2. PROCESSORS: "How should we transform it?" (batch, add attributes)
# 3. EXPORTERS: "Where does it go?" (ClickHouse via SigNoz)
# 4. SERVICE: "Wire it all together into pipelines"

# =============================================================================
# RECEIVERS
# =============================================================================
# Receivers define how the collector accepts incoming telemetry data.
# OTLP (OpenTelemetry Protocol) is the standard protocol for OTel data.
#
receivers:
  # OTLP receiver accepts traces, metrics, and logs
  otlp:
    protocols:
      # gRPC on port 4317 - efficient binary protocol, preferred for backends
      grpc:
        endpoint: 0.0.0.0:4317
      # HTTP on port 4318 - useful for browsers or when gRPC isn't available
      http:
        endpoint: 0.0.0.0:4318

# =============================================================================
# PROCESSORS
# =============================================================================
# Processors transform data between receiving and exporting.
# They can batch, filter, add attributes, sample, and more.
#
processors:
  # Batch processor groups telemetry data before sending to exporters.
  # Why batch?
  # - Reduces network overhead (fewer, larger requests)
  # - Improves compression (more data to compress together)
  # - Allows retries at the batch level
  batch:
    # Send a batch when it has 1000 items OR after 5 seconds, whichever comes first
    send_batch_size: 1000
    timeout: 5s
    # Maximum items in a batch (prevents memory issues with high traffic)
    send_batch_max_size: 1500

  # Memory limiter prevents the collector from using too much RAM
  # If memory exceeds the limit, it will drop data rather than crash
  memory_limiter:
    # Start refusing data when memory hits 400MB
    limit_mib: 400
    # Start dropping data aggressively when memory hits 350MB
    spike_limit_mib: 100
    # How often to check memory usage
    check_interval: 5s

  # Resource detection adds information about where the collector is running
  # This helps identify which host/container data came from
  resourcedetection:
    detectors:
      - env           # Read from OTEL_RESOURCE_ATTRIBUTES env var
      - system        # Add host.name, os.type, etc.
    timeout: 5s
    override: false   # Don't override attributes set by the application

# =============================================================================
# EXPORTERS
# =============================================================================
# Exporters send processed telemetry to backends for storage and visualization.
#
exporters:
  # ClickHouse exporter sends data to SigNoz's ClickHouse database
  clickhousetraces:
    datasource: tcp://clickhouse:9000/?database=signoz_traces
    migrations_folder: /migrations/traces
    # Low traffic threshold for optimization
    low_cardinal_exception_grouping: true

  clickhousemetrics:
    datasource: tcp://clickhouse:9000/?database=signoz_metrics

  clickhouselogs:
    datasource: tcp://clickhouse:9000/?database=signoz_logs

  # Debug exporter (commented out) - useful for troubleshooting
  # Uncomment to see all telemetry data in collector logs
  # debug:
  #   verbosity: detailed

# =============================================================================
# EXTENSIONS
# =============================================================================
# Extensions provide capabilities that don't fit the pipeline model.
#
extensions:
  # Health check endpoint - other services can verify the collector is running
  # Used by Docker healthcheck and load balancers
  health_check:
    endpoint: 0.0.0.0:13133

  # Prometheus metrics about the collector itself
  # Useful for monitoring collector performance (queue depth, dropped items, etc.)
  zpages:
    endpoint: 0.0.0.0:55679

# =============================================================================
# SERVICE
# =============================================================================
# The service section wires everything together into pipelines.
# Each pipeline type (traces, metrics, logs) can have different configurations.
#
service:
  # Enable the extensions
  extensions: [health_check, zpages]

  # Define the pipelines
  pipelines:
    # Traces pipeline: captures request journeys through your system
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [clickhousetraces]

    # Metrics pipeline: captures counts, gauges, histograms
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [clickhousemetrics]

    # Logs pipeline: captures structured log entries
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [clickhouselogs]

  # Collector's own telemetry (for monitoring the collector)
  telemetry:
    logs:
      level: info
    metrics:
      address: 0.0.0.0:8888
